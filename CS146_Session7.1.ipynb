{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS146 Session 7.1 PCW \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using normal approximation to the binomial distributon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8593850969136854"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "p = 0.1 \n",
    "q = 1-p \n",
    "\n",
    "mean = n*p\n",
    "std = np.sqrt(n*p*q)\n",
    "\n",
    "norm = stats.norm(loc = n*p, scale = np.sqrt(n*p*q))\n",
    "\n",
    "(abs(mean - norm.interval(0.95)[1]))/1000 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MOE (n, p):\n",
    "    norm = stats.norm(loc = n*p, scale = np.sqrt(n*p*(1-p)))\n",
    "    \n",
    "    return ((norm.interval(0.95)[1] - (n*p))/n) * 100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8798919536201595"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test \n",
    "\n",
    "MOE(100, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [1000, 750, 500, 250, 100]\n",
    "\n",
    "per_10 = []\n",
    "per_20 = []\n",
    "per_30 = []\n",
    "per_40 = []\n",
    "per_50 = []\n",
    "per_60 = []\n",
    "per_70 = []\n",
    "per_80 = []\n",
    "per_90 = []\n",
    "\n",
    "rounding = 0\n",
    "\n",
    "for sample in sample_sizes:\n",
    "    per_10.append(np.round(MOE(sample, 0.1), rounding))\n",
    "    per_20.append(np.round(MOE(sample, 0.2), rounding))\n",
    "    per_30.append(np.round(MOE(sample, 0.3), rounding))\n",
    "    per_40.append(np.round(MOE(sample, 0.4), rounding))\n",
    "    per_50.append(np.round(MOE(sample, 0.5), rounding))\n",
    "    per_60.append(np.round(MOE(sample, 0.6), rounding))\n",
    "    per_70.append(np.round(MOE(sample, 0.7), rounding))\n",
    "    per_80.append(np.round(MOE(sample, 0.8), rounding))\n",
    "    per_90.append(np.round(MOE(sample, 0.9), rounding))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Margin Matrix\n",
      "[2.0, 2.0, 3.0, 4.0, 6.0]\n",
      "[2.0, 3.0, 4.0, 5.0, 8.0]\n",
      "[3.0, 3.0, 4.0, 6.0, 9.0]\n",
      "[3.0, 4.0, 4.0, 6.0, 10.0]\n",
      "[3.0, 4.0, 4.0, 6.0, 10.0]\n",
      "[3.0, 4.0, 4.0, 6.0, 10.0]\n",
      "[3.0, 3.0, 4.0, 6.0, 9.0]\n",
      "[2.0, 3.0, 4.0, 5.0, 8.0]\n",
      "[2.0, 2.0, 3.0, 4.0, 6.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Margin Matrix\")\n",
    "print(per_10)\n",
    "print(per_20)\n",
    "print(per_30)\n",
    "print(per_40)\n",
    "print(per_50)\n",
    "print(per_60)\n",
    "print(per_70)\n",
    "print(per_80)\n",
    "print(per_90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning and Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As compared to the table, percentages after 30 seem to be very different from my error margin matrix. \n",
    "\n",
    "I am not quite sure to say where the errors are coming from in the table and why there is a huge difference at higher percentages. We do see a similar trend that as we increase the sample size (from right to left), the errors decrease. I do not have any information how exactly Roper calculated its margin of error which is safe to say that there may be other factors that may have been included such as weights, process of acquiring marign of errors that can contribute to the difference that we have discovered here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
